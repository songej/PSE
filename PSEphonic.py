import streamlit as st
import requests
import re
import pandas as pd
import time
from bs4 import BeautifulSoup
from functools import lru_cache

st.set_page_config(page_title="PhonicFind", page_icon="ğŸ” ")

st.markdown(
    """
    <style>
    @media (max-width: 768px) {
        .block-container { padding-top: 1rem; }
        .stButton button { font-size: 16px; padding: 8px; }
        .stMarkdown p { font-size: 16px; }
    }
    </style>
    """, unsafe_allow_html=True
)

st.title("PhonicFind: ë°œìŒê¸°í˜¸ ì°¾ê¸°")

st.write("ë°œìŒê¸°í˜¸ë¥¼ ê°€ì ¸ì˜¬ ë‹¨ì–´ ëª©ë¡ì„ ì…ë ¥í•˜ì„¸ìš”. (í•œ ì¤„ì— í•˜ë‚˜ì”©)")
word_list = list(filter(None, map(str.strip, st.text_area("ë‹¨ì–´ ì…ë ¥:", height=200).splitlines())))

# Daum ì‚¬ì „ì—ì„œ ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ ì •ì˜
@lru_cache(maxsize=5000)
def get_phonetic_from_daum(word, retries=3):
    url = f"https://dic.daum.net/search.do?q={word}"
    for attempt in range(retries):
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            phonetic = soup.find('span', {'class': 'txt_pronounce'})
            if phonetic:
                return phonetic.get_text()
            return "[N/A]"  # ë°œìŒê¸°í˜¸ê°€ ì—†ëŠ” ê²½ìš°
        except requests.exceptions.RequestException as e:
            if attempt < retries - 1:  # ì¬ì‹œë„ ê°€ëŠ¥
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ì  ì§€ì—°
                continue
            st.error(f"ì›¹ ìš”ì²­ ì˜¤ë¥˜ ë°œìƒ ({word}): {e}")
            return "[N/A]"

# ë³µìˆ˜í˜•ì„ ë‹¨ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
@lru_cache(maxsize=1000)
def get_singular(word):
    if word.endswith('ies') and len(word) > 3:
        return word[:-3] + 'y'
    elif word.endswith('es') and len(word) > 2:
        return word[:-2]
    elif word.endswith('s') and len(word) > 1:
        return word[:-1]
    return word

# ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°
@lru_cache(maxsize=5000)
def get_phonetic(word, api_key, retries=3):
    for attempt in range(retries):
        try:
            response = requests.get(API_URL.format(word, api_key), timeout=10)
            response.raise_for_status()
            data = response.json()
            if isinstance(data, list) and data and 'hwi' in data[0] and 'prs' in data[0]['hwi']:
                return data[0]['hwi']['prs'][0].get('mw', "N/A")
            return "N/A"
        except requests.exceptions.RequestException as e:
            if attempt < retries - 1:  # ì¬ì‹œë„ ê°€ëŠ¥
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ì  ì§€ì—°
                continue
            st.error(f"API ì˜¤ë¥˜ ë°œìƒ ({word}): {e}")
            return "N/A"

# ì¶”ê°€ ìºì‹±ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
na_cache = set()  # ì´ë¯¸ N/Aë¡œ í™•ì¸ëœ ë‹¨ì–´ë¥¼ ì €ì¥

# PSE ë³€í™˜ ê·œì¹™
conversion_table = {
    "auÌ‡": "É‘u",
    "È¯iììŒ": "oi:",
    "È¯i": "oi",
    "Ä«ììŒ": "É‘i:",
    "Ä«": "É‘i",
    "ÄììŒ": "ei:",
    "Ä": "ei",
    "È¯r": "or",
    "Ã¤r": "É”:r",
    "uÌ‡r": "u:r",
    "È¯": "É”:",
    "Ã¼": "u:",
    "Ä“": "i:",
    "uÌ‡": "u",
    "i": "i",
    "e": "e",
    "É™": "ÊŒ",
    "Ã¤": "É‘:",
    "a": "Ã¦",
    "Å": "ou",
    "É™r": "É™r",
    "er": "er",
    "ir": "i:r",
    "j": "Ê¤",
    "sh": "Êƒ"
}

# ëª¨ìŒ ê°•ì„¸ ê¸°í˜¸
vowel_mapping = {
    "i": "Ã­",
    "e": "Ã©",
    "ÊŒ": "ÊŒÌ",
    "É‘:": "É‘Ì:",
    "Ã¦": "Ç½",
    "É”:": "É”Ì:",
    "u:": "Ãº:",
    "i:": "Ã­:",
    "É™": "É™Ì",
    "u": "Ãº",
    "É‘i": "É‘Ìi",
    "É‘i:": "É‘Ìi:",
    "ei": "Ã©i",
    "ei:": "Ã©i:",
    "oi": "Ã³i",
    "oi:": "Ã³i:",
    "ou": "Ã³u",
    "É‘u": "É‘Ìu",
    "É™r": "É™Ìr",
    "er": "Ã©r",
    "i:r": "Ã­:r",
    "or": "Ã³r",
    "É”:r": "É”Ì:r",
    "u:r": "Ãº:r"
}

# ììŒ ì •ì˜
consonant_pattern = r"[bcdfghjklmnpqrstvwxyz]"

# PSE ê·œì¹™ ë³€í™˜
def convert_to_pse(ipa: str) -> str:
    # 1. PSE ë³€í™˜ ê·œì¹™ ì ìš©
    for pattern, pse in conversion_table.items():
        if pattern.endswith("ììŒ"):
            base_pattern = pattern[:-2]
            ipa = re.sub(f"{base_pattern}(?={consonant_pattern})", pse, ipa)
        else:
            ipa = ipa.replace(pattern, pse)

    # 2. ê°•ì„¸ ê¸°í˜¸ ë³€í™˜: ëª¨ë“  `Ëˆ` ë’¤ì˜ ì²« ëª¨ìŒ íŒ¨í„´ì— ê°•ì„¸ ê¸°í˜¸ë¥¼ í•œ ë²ˆì— ì ìš©
    ipa = re.sub(
        r"Ëˆ((?:É‘i|ei|oi|ou|É‘u|[iueÉ”ÊŒÉ™É‘Ã¦]+:?r?))",  # ëª¨ë“  ëª¨ìŒ íŒ¨í„´ì— ëŒ€ì‘
        lambda m: vowel_mapping.get(m.group(1), m.group(1)),
        ipa
    )

    # 3. ë³€í™˜ í›„ ëª¨ë“  `Ëˆ` ê¸°í˜¸ ì œê±°
    ipa = ipa.replace("Ëˆ", "")
    
    return ipa

# ê° ë‹¨ì–´ì˜ ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸° - ìµœì í™”ëœ í•¨ìˆ˜
def process_word(word):
    tokens = re.split(r'([ \-/,;.!?:])', word)
    phonetic_tokens = []
    for token in tokens:
        if re.match(r'[ \-/,;.!?:]', token):
            phonetic_tokens.append(token)
        elif token.strip():
            transcription = get_phonetic_from_daum(token)
            phonetic_tokens.append(transcription)
    return ''.join(phonetic_tokens)

# ì„¸ì…˜ ìƒíƒœë¡œ ê²°ê³¼ ì €ì¥
if "results_df" not in st.session_state:
    st.session_state["results_df"] = pd.DataFrame()

# ë²„íŠ¼ ì„ íƒ ì‹œ ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°
if st.button("ë°œìŒê¸°í˜¸ ì•Œì•„ë³´ê¸°"):
    if word_list:
        with st.spinner("ë°œìŒê¸°í˜¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            results = []
            missing_words = []
            processing_status = st.empty()
            for idx, word in enumerate(word_list, start=1):
                processing_status.info(f"{idx}/{len(word_list)}: '{word}' ì²˜ë¦¬ ì¤‘...")
                transcription = process_word(word)
                pse_transcription = convert_to_pse(transcription)  # PSE ë°œìŒê¸°í˜¸
                results.append((word, transcription, pse_transcription))
                if "[N/A]" in transcription:
                    missing_words.append(word)

            # ê²°ê³¼ ì„¸ì…˜ ì €ì¥
            df = pd.DataFrame(results, columns=["Word", "Phonetic (with Stress)", "PSE"])
            df.index += 1
            st.session_state["results_df"] = df
            if missing_words:
                st.warning(f"ë°œìŒê¸°í˜¸ë¥¼ ì°¾ì§€ ëª»í•œ ë‹¨ì–´: {', '.join(missing_words)}")

# ê²°ê³¼ ì¶œë ¥
if not st.session_state["results_df"].empty:
    df = st.session_state["results_df"]

    # ê²°ê³¼í‘œ ìŠ¤íƒ€ì¼ë§
    def highlight_cells(value):
        if '[N/A]' in value:
            return 'background-color: red; color: white;'
        elif '[' in value and ']' in value:
            return 'background-color: yellow;'
        return ''

    # ê²°ê³¼í‘œ ì¶œë ¥
    st.write("(PSE ë°œìŒê¸°í˜¸ í‘œê¸°ëŠ” ë³´ì™„ ì¤‘ì…ë‹ˆë‹¤.)")
    styled_df = df.style.applymap(highlight_cells, subset=['Phonetic (with Stress)', 'PSE'])
    st.dataframe(styled_df, use_container_width=True)

    # CSV ë‹¤ìš´ë¡œë“œ (UTF-8 with BOM)
    csv = df.to_csv(index=True, encoding='utf-8-sig').encode('utf-8-sig')
    st.download_button(
        label="ë°œìŒê¸°í˜¸ ëª©ë¡ ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name='PhonicFind.csv',
        mime='text/csv'
    )
