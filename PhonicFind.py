import streamlit as st
import requests
import re
import pandas as pd
import time
from functools import lru_cache

st.set_page_config(page_title="PhonicFind", page_icon="ğŸ” ")

st.markdown(
    """
    <style>
    @media (max-width: 768px) {
        .block-container { padding-top: 1rem; }
        .stButton button { font-size: 16px; padding: 8px; }
        .stMarkdown p { font-size: 16px; }
    }
    </style>
    """, unsafe_allow_html=True
)

st.title("PhonicFind: ë°œìŒê¸°í˜¸ ì°¾ê¸°")

st.markdown("""
ë©”ë¦¬ì—„-ì›¹ìŠ¤í„° ì‚¬ì „ì—ì„œ ë¬´ë£Œë¡œ ì œê³µí•˜ëŠ” API í‚¤ë¥¼ ì…ë ¥í•˜ê³ ,  
í•˜ë£¨ì— 1000 ë‹¨ì–´ê¹Œì§€ í•œêº¼ë²ˆì— ë°œìŒê¸°í˜¸ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.
1. Merriam-Webster's Developer Center [íšŒì›ê°€ì…](https://dictionaryapi.com/register/index)
   - Request API Key (1) ì—ëŠ” Collegiate Dictionary ì„ íƒ
   - Request API Key (2) ì—ëŠ” Learners Dictionary ì„ íƒ
2. ì´ë©”ì¼ ì¸ì¦í•˜ê³  [ë¡œê·¸ì¸](https://dictionaryapi.com/sign-in)
3. [Your Keys í˜ì´ì§€](https://dictionaryapi.com/account/my-keys) ì—ì„œ Key (Dictionary): ë¶€ë¶„ì˜ ì½”ë“œë¥¼ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸°
""")
API_KEY = st.text_input("API Key ì…ë ¥:", type="password")

st.write("ë°œìŒê¸°í˜¸ë¥¼ ê°€ì ¸ì˜¬ ë‹¨ì–´ ëª©ë¡ì„ ì…ë ¥í•˜ì„¸ìš”. (í•œ ì¤„ì— í•˜ë‚˜ì”©)")
word_list = list(filter(None, map(str.strip, st.text_area("ë‹¨ì–´ ì…ë ¥:", height=200).splitlines())))

API_URL = "https://www.dictionaryapi.com/api/v3/references/collegiate/json/{}?key={}"

# ë³µìˆ˜í˜•ì„ ë‹¨ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
@lru_cache(maxsize=1000)
def get_singular(word):
    if word.endswith('ies') and len(word) > 3:
        return word[:-3] + 'y'
    elif word.endswith('es') and len(word) > 2:
        return word[:-2]
    elif word.endswith('s') and len(word) > 1:
        return word[:-1]
    return word

# ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°
@lru_cache(maxsize=5000)
def get_phonetic(word, api_key, retries=3):
    for attempt in range(retries):
        try:
            response = requests.get(API_URL.format(word, api_key), timeout=10)
            response.raise_for_status()
            data = response.json()
            if isinstance(data, list) and data and 'hwi' in data[0] and 'prs' in data[0]['hwi']:
                return data[0]['hwi']['prs'][0].get('mw', "N/A")
            return "N/A"
        except requests.exceptions.RequestException as e:
            if attempt < retries - 1:  # ì¬ì‹œë„ ê°€ëŠ¥
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ì  ì§€ì—°
                continue
            st.error(f"API ì˜¤ë¥˜ ë°œìƒ ({word}): {e}")
            return "N/A"

# ê° ë‹¨ì–´ì˜ ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°
def process_word(word, api_key): 
    tokens = re.split(r'([ \-/,;.!?:])', word)
    phonetic_tokens = []
    delay = 0.1  # ê¸°ë³¸ ì§€ì—° ì‹œê°„
    for token in tokens:
        if re.match(r'[ \-/,;.!?:]', token):
            phonetic_tokens.append(token)
        elif token.strip():
            transcription = get_phonetic(token, api_key)
            if transcription == "N/A":
                singular_form = get_singular(token)
                if singular_form != token:
                    transcription = get_phonetic(singular_form, api_key)
                    if transcription != "N/A":
                        transcription += f" [{singular_form}]"
            phonetic_tokens.append(transcription if transcription != "N/A" else "[N/A]")
            time.sleep(delay)
            delay = min(delay + 0.05, 0.5)
    return ''.join(phonetic_tokens)

# PSE ë³€í™˜ ê·œì¹™
# ë³€í™˜ í‘œ ì •ì˜ (ê¸´ ë¬¸ìì—´ ìš°ì„  ìˆœìœ„ ë° ìƒˆë¡œìš´ ê·œì¹™ í¬í•¨)
conversion_table = {
    "auÌ‡": "É‘u",
    "È¯iììŒ": "oi:",  # ììŒì´ ë’¤ë”°ë¥´ëŠ” ê²½ìš°
    "È¯i": "oi",
    "Ä«ììŒ": "É‘i:",
    "Ä«": "É‘i",
    "ÄììŒ": "ei:",
    "Ä": "ei",
    "È¯r": "or",
    "Ã¤r": "É”:r",
    "uÌ‡r": "u:r",
    "È¯": "É”:",
    "Ã¼": "u:",
    "Ä“": "i:",
    "uÌ‡": "u",
    "i": "i",
    "e": "e",
    "É™": "ÊŒ",
    "Ã¤": "É‘:",
    "a": "Ã¦",
    "Å": "ou",
    "É™r": "É™r",
    "er": "er",
    "ir": "i:r",
    "j": "Ê¤",
    "sh": "Êƒ"
}

# ëª¨ë“  ëª¨ìŒì— ëŒ€ì‘í•˜ëŠ” ê°•ì„¸ ê¸°í˜¸ ë§¤í•‘
vowel_mapping = {
    "a": "Ç½",
    "e": "Ã©",
    "i": "Ã­",
    "o": "Ã³",
    "u": "Ãº",
    "É™": "É™Ì",
    "Ã¤": "Ç½",
    "È¯": "Ç¿",
    "Ã¼": "Ç˜",
    "Ä“": "á¸—",
    "Ä«": "á¸¯",
    "Ä": "Ç£",
    "Å": "á¹“",
    "uÌ‡": "á¹¹"
}

# ììŒ ì •ì˜
consonant_pattern = r"[bcdfghjklmnpqrstvwxyz]"

# PSE ê·œì¹™ ë³€í™˜
def convert_to_pse(ipa: str) -> str:
    ipa = re.sub(
        r"Ëˆ([aeiouÉ™Ã¤È¯Ã¼Ä“Ä«ÄÅuÌ‡])",  # Ëˆë’¤ì˜ ì²«ëª¨ìŒ ê°•ì„¸
        lambda m: vowel_mapping.get(m.group(1), m.group(1)),
        ipa,
        count=1
    )
    
    for pattern, pse in conversion_table.items():
        if pattern.endswith("ììŒ"):  # ììŒ ì—¬ë¶€ë¥¼ íŒë‹¨
            base_pattern = pattern[:-2]
            if re.match(f"^{base_pattern}({consonant_pattern})", ipa):
                return pse
        elif ipa.startswith(pattern):
            return pse
    return ipa

# API Key ìœ íš¨ì„± ê²€ì¦
def validate_api_key(api_key):
    test_word = "test"
    try:
        response = requests.get(API_URL.format(test_word, api_key), timeout=10)
        response.raise_for_status()
        data = response.json()
        return isinstance(data, list)
    except requests.exceptions.RequestException:
        return False

# ì„¸ì…˜ ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ ì €ì¥
if "results_df" not in st.session_state:
    st.session_state["results_df"] = pd.DataFrame()

# ë²„íŠ¼ ì„ íƒ ì‹œ ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°
if st.button("ë°œìŒê¸°í˜¸ ì•Œì•„ë³´ê¸°"):
    if not API_KEY:
        st.error("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif not validate_api_key(API_KEY):
        st.error("ìœ íš¨í•˜ì§€ ì•Šì€ API Keyì…ë‹ˆë‹¤. ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    elif word_list:
        with st.spinner("ë°œìŒê¸°í˜¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            results = []
            missing_words = []
            processing_status = st.empty()
            for idx, word in enumerate(word_list, start=1):
                processing_status.info(f"{idx}/{len(word_list)}: '{word}' ì²˜ë¦¬ ì¤‘...")
                transcription = process_word(word, API_KEY)
                pse_transcription = convert_to_pse(transcription)  # PSE ë°œìŒê¸°í˜¸
                results.append((word, transcription, pse_transcription))
                if "[N/A]" in transcription:
                    missing_words.append(word)

            # ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            df = pd.DataFrame(results, columns=["Word", "Phonetic (with Stress)", "PSE"])
            df.index += 1
            st.session_state["results_df"] = df
            if missing_words:
                st.warning(f"ë°œìŒê¸°í˜¸ë¥¼ ì°¾ì§€ ëª»í•œ ë‹¨ì–´: {', '.join(missing_words)}")

# ê²°ê³¼ ì¶œë ¥
if not st.session_state["results_df"].empty:
    df = st.session_state["results_df"]

    # ê²°ê³¼í‘œ ìŠ¤íƒ€ì¼ë§
    def highlight_cells(value):
        if '[N/A]' in value:
            return 'background-color: red; color: white;'
        elif '[' in value and ']' in value:
            return 'background-color: yellow;'
        return ''

    # ê²°ê³¼í‘œ ì¶œë ¥
    styled_df = df.style.applymap(highlight_cells, subset=['Phonetic (with Stress)', 'PSE'])
    st.write(styled_df)

    # CSV ë‹¤ìš´ë¡œë“œ (UTF-8 with BOM)
    csv = df.to_csv(index=True, encoding='utf-8-sig').encode('utf-8-sig')
    st.download_button(
        label="ë°œìŒê¸°í˜¸ ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name='PhonicFind.csv',
        mime='text/csv'
    )
