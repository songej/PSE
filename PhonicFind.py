import streamlit as st
import requests
import re
import pandas as pd
import time
from functools import lru_cache

st.set_page_config(page_title="PhonicFind", page_icon="ğŸ” ")

st.markdown(
    """
    <style>
    @media (max-width: 768px) {
        .block-container { padding-top: 1rem; }
        .stButton button { font-size: 16px; padding: 8px; }
        .stMarkdown p { font-size: 16px; }
    }
    </style>
    """, unsafe_allow_html=True
)

st.title("PhonicFind: PSE ë°œìŒì°¾ê¸°")

st.markdown("""
ë©”ë¦¬ì—„-ì›¹ìŠ¤í„° ì‚¬ì „ì—ì„œ ë¬´ë£Œë¡œ ì œê³µí•˜ëŠ” API í‚¤ë¥¼ ì…ë ¥í•˜ê³ ,  
í•˜ë£¨ì— 1000 ë‹¨ì–´ê¹Œì§€ í•œêº¼ë²ˆì— ë°œìŒê¸°í˜¸ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.
1. Merriam-Webster's Developer Center [íšŒì›ê°€ì…](https://dictionaryapi.com/register/index)
   - Request API Key (1) ì—ëŠ” Collegiate Dictionary ì„ íƒ
   - Request API Key (2) ì—ëŠ” Learners Dictionary ì„ íƒ
2. ì´ë©”ì¼ ì¸ì¦í•˜ê³  [ë¡œê·¸ì¸](https://dictionaryapi.com/sign-in)
3. [Your Keys í˜ì´ì§€](https://dictionaryapi.com/account/my-keys) ì—ì„œ Key (Dictionary): ë¶€ë¶„ì˜ ì½”ë“œë¥¼ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸°
""")
API_KEY = st.text_input("API Key ì…ë ¥:", type="password")

st.write("ë°œìŒê¸°í˜¸ë¥¼ ê°€ì ¸ì˜¬ ë‹¨ì–´ ëª©ë¡ì„ ì…ë ¥í•˜ì„¸ìš”. (í•œ ì¤„ì— í•˜ë‚˜ì”©)")
word_list = list(filter(None, map(str.strip, st.text_area("ë‹¨ì–´ ì…ë ¥:", height=200).splitlines())))

API_URL = "https://www.dictionaryapi.com/api/v3/references/collegiate/json/{}?key={}"

# ë³µìˆ˜í˜•ì„ ë‹¨ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
@lru_cache(maxsize=1000)
def get_singular(word):
    if word.endswith('ies') and len(word) > 3:
        return word[:-3] + 'y'
    elif word.endswith('es') and len(word) > 2:
        return word[:-2]
    elif word.endswith('s') and len(word) > 1:
        return word[:-1]
    return word

# ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°
@lru_cache(maxsize=5000)  # ìºì‹œ í¬ê¸° ì¡°ì •
def get_phonetic(word, api_key):
    try:
        response = requests.get(API_URL.format(word, api_key), timeout=10)
        response.raise_for_status()
        data = response.json()
        if isinstance(data, list) and data and 'hwi' in data[0] and 'prs' in data[0]['hwi']:
            return data[0]['hwi']['prs'][0].get('mw', "N/A")
        return "N/A"
    except requests.exceptions.RequestException as e:
        st.error(f"API ì˜¤ë¥˜ ë°œìƒ ({word}): {e}")
    return "N/A"

# ê° ë‹¨ì–´ì˜ ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°
def process_word(word, api_key): 
    tokens = re.split(r'([ \-/,;.!?:])', word)
    phonetic_tokens = []
    delay = 0.1  # ê¸°ë³¸ ì§€ì—° ì‹œê°„
    for token in tokens:
        if re.match(r'[ \-/,;.!?:]', token):
            phonetic_tokens.append(token)
        elif token.strip():
            transcription = get_phonetic(token, api_key)
            if transcription == "N/A":
                singular_form = get_singular(token)
                if singular_form != token:
                    transcription = get_phonetic(singular_form, api_key)
                    if transcription != "N/A":
                        transcription += f" [{singular_form}]"
            phonetic_tokens.append(transcription if transcription != "N/A" else "[N/A]")
            time.sleep(delay)
            delay = min(delay + 0.05, 0.5)  # ìš”ì²­ ë¹ˆë„ ì œí•œì„ ì ì§„ì ìœ¼ë¡œ ë†’ì„
    return ''.join(phonetic_tokens)

# API Key ìœ íš¨ì„± ê²€ì¦
def validate_api_key(api_key):
    test_word = "test"
    try:
        response = requests.get(API_URL.format(test_word, api_key), timeout=10)
        response.raise_for_status()
        data = response.json()
        return isinstance(data, list)
    except requests.exceptions.RequestException:
        return False

# ì„¸ì…˜ ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ ì €ì¥
if "results_df" not in st.session_state:
    st.session_state["results_df"] = pd.DataFrame()

# ë²„íŠ¼ ì„ íƒ ì‹œ ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°
if st.button("ë°œìŒê¸°í˜¸ ì•Œì•„ë³´ê¸°"):
    if not API_KEY:
        st.error("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif not validate_api_key(API_KEY):
        st.error("ìœ íš¨í•˜ì§€ ì•Šì€ API Keyì…ë‹ˆë‹¤. ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    elif word_list:
        with st.spinner("ë°œìŒê¸°í˜¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            results = []
            missing_words = []
            for idx, word in enumerate(word_list, start=1):
                st.info(f"{idx}/{len(word_list)}: '{word}' ì²˜ë¦¬ ì¤‘...")
                transcription = process_word(word, API_KEY)
                results.append((word, transcription))
                if "[N/A]" in transcription:
                    missing_words.append(word)
                
            df = pd.DataFrame(results, columns=["Word", "Phonetic (with Stress)"])
            df.index += 1
            st.session_state["results_df"] = df
            if missing_words:
                st.warning(f"ë°œìŒê¸°í˜¸ë¥¼ ì°¾ì§€ ëª»í•œ ë‹¨ì–´ë“¤: {', '.join(missing_words)}")

# ê²°ê³¼í‘œ ì„¸ì…˜ ìœ ì§€
if not st.session_state["results_df"].empty:
    df = st.session_state["results_df"]

    # ê²°ê³¼í‘œ ìŠ¤íƒ€ì¼ë§
    def highlight_na(value):
        return 'background-color: yellow' if '[N/A]' in value else ''
    styled_df = df.style.applymap(highlight_na, subset=['Phonetic (with Stress)'])
    st.table(styled_df)

    # CSV ë‹¤ìš´ë¡œë“œ (UTF-8 with BOM)
    csv = df.to_csv(index=True, encoding='utf-8-sig').encode('utf-8-sig')
    st.download_button(
        label="ê²°ê³¼í‘œ ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name='phonetic_transcriptions.csv',
        mime='text/csv'
    )
