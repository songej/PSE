import streamlit as st
import requests
import re
import pandas as pd
import time
import io
from functools import lru_cache

st.set_page_config(page_title="PhonicFind", page_icon="ğŸ” ")

st.markdown(
    """
    <style>
    @media (max-width: 768px) {
        .block-container {
            padding-top: 1rem;
        }
        .stButton button {
            font-size: 16px;
            padding: 8px;
        }
        .stMarkdown p {
            font-size: 16px;
        }
    }
    </style>
    """, unsafe_allow_html=True
)

st.title("PhonicFind: PSE ë°œìŒì°¾ê¸°")

st.markdown("""
ë©”ë¦¬ì—„-ì›¹ìŠ¤í„° ì‚¬ì „ì—ì„œ ë¬´ë£Œë¡œ ì œê³µí•˜ëŠ” API í‚¤ë¥¼ ì…ë ¥í•˜ê³ ,  
í•˜ë£¨ì— 1000 ë‹¨ì–´ê¹Œì§€ í•œêº¼ë²ˆì— ë°œìŒê¸°í˜¸ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.
1. Merriam-Webster's Developer Center [íšŒì›ê°€ì…](https://dictionaryapi.com/register/index)
   - Request API Key (1) ì—ëŠ” Collegiate Dictionary ì„ íƒ
   - Request API Key (2) ì—ëŠ” Learners Dictionary ì„ íƒ
2. ì´ë©”ì¼ ì¸ì¦í•˜ê³  [ë¡œê·¸ì¸](https://dictionaryapi.com/sign-in)
3. [Your Keys í˜ì´ì§€](https://dictionaryapi.com/account/my-keys) ì—ì„œ Key (Dictionary): ë¶€ë¶„ì˜ ì½”ë“œë¥¼ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸°
""")

API_KEY = st.text_input("API Key ì…ë ¥:", type="password")
st.write("ë°œìŒê¸°í˜¸ë¥¼ ê°€ì ¸ì˜¬ ë‹¨ì–´ ëª©ë¡ì„ ì…ë ¥í•˜ì„¸ìš”. (í•œ ì¤„ì— í•˜ë‚˜ì”©)")
word_list = list(filter(None, map(str.strip, st.text_area("ë‹¨ì–´ ì…ë ¥:", height=200).splitlines())))

API_URL = "https://www.dictionaryapi.com/api/v3/references/collegiate/json/{}?key={}"

@lru_cache(maxsize=1000)
def get_singular(word):
    """ë³µìˆ˜í˜•ì„ ë‹¨ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜"""
    if word.endswith('ies') and len(word) > 3:
        return word[:-3] + 'y'
    elif word.endswith('es') and len(word) > 2:
        return word[:-2]
    elif word.endswith('s') and len(word) > 1:
        return word[:-1]
    return word

@lru_cache(maxsize=1000)
def get_phonetic(word):
    """ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = requests.get(API_URL.format(word, API_KEY), timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if isinstance(data, list) and data and 'hwi' in data[0] and 'prs' in data[0]['hwi']:
            return data[0]['hwi']['prs'][0].get('mw', "N/A")
        else:
            return "N/A"
    except requests.exceptions.RequestException as e:
        st.error(f"API ì˜¤ë¥˜ ë°œìƒ ({word}): {e}")
    except (ValueError, KeyError, IndexError):
        st.error(f"API ì‘ë‹µ ì˜¤ë¥˜ ({word}): API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    return "N/A"

def process_word(word): 
    """ê° ë‹¨ì–´ì˜ ë°œìŒê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°"""
    tokens = re.split(r'([ \-/,;.!?:])', word)
    phonetic_tokens = []
    for token in tokens:
        if re.match(r'[ \-/,;.!?:]', token):
            phonetic_tokens.append(token)
        elif token.strip():
            transcription = get_phonetic(token)
            if transcription == "N/A":
                singular_form = get_singular(token)
                if singular_form != token:
                    transcription = get_phonetic(singular_form)
                    if transcription != "N/A":
                        transcription += f" [{singular_form}]"
            phonetic_tokens.append(transcription if transcription != "N/A" else "[N/A]")
            time.sleep(0.1)
    return ''.join(phonetic_tokens)

def validate_api_key(api_key):
    """API Key ìœ íš¨ì„± ê²€ì¦"""
    test_word = "test"
    try:
        response = requests.get(API_URL.format(test_word, api_key), timeout=10)
        response.raise_for_status()
        data = response.json()
        return isinstance(data, list)
    except requests.exceptions.RequestException:
        return False

if "results_df" not in st.session_state:
    st.session_state["results_df"] = pd.DataFrame()

if st.button("ë°œìŒê¸°í˜¸ ì•Œì•„ë³´ê¸°"):
    if not API_KEY:
        st.error("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif not validate_api_key(API_KEY):
        st.error("ìœ íš¨í•˜ì§€ ì•Šì€ API Keyì…ë‹ˆë‹¤. ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    elif word_list:
        with st.spinner("ë°œìŒê¸°í˜¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            results = []
            missing_words = []
            for idx, word in enumerate(word_list, start=1):
                st.info(f"{idx}/{len(word_list)}: '{word}' ì²˜ë¦¬ ì¤‘...")
                transcription = process_word(word)
                results.append((word, transcription))
                if "[N/A]" in transcription:
                    missing_words.append(word)
                
            df = pd.DataFrame(results, columns=["Word", "Phonetic (with Stress)"])
            df.index += 1
            st.session_state["results_df"] = df  # ê²°ê³¼í‘œ ì„¸ì…˜ ì €ì¥
            if missing_words:
                st.warning(f"ë°œìŒê¸°í˜¸ë¥¼ ì°¾ì§€ ëª»í•œ ë‹¨ì–´ë“¤: {', '.join(missing_words)}")

# ê²°ê³¼í‘œ ì„¸ì…˜ ìœ ì§€
if not st.session_state["results_df"].empty:
    df = st.session_state["results_df"]
    def highlight_na(value):
        return 'background-color: yellow' if '[N/A]' in value else ''
    styled_df = df.style.applymap(highlight_na, subset=['Phonetic (with Stress)'])
    st.table(styled_df)

    # CSV ë‹¤ìš´ë¡œë“œ (UTF-8 with BOM)
    csv = df.to_csv(index=True, encoding='utf-8-sig').encode('utf-8-sig')
    st.download_button(
        label="ê²°ê³¼í‘œ ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name='phonetic_transcriptions.csv',
        mime='text/csv'
    )
